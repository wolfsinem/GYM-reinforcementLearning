{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 1_Hogeschool-Utrecht_Reinforcement-Learning-project_Q-Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wolfsinem/GYM-reinforcementLearning/blob/main/Copy_of_1_Hogeschool_Utrecht_Reinforcement_Learning_project_Q_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eU2QJ--T4dd"
      },
      "source": [
        "# Reinforcement Learning project - Q-Learning\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qdkwbpRUhzO"
      },
      "source": [
        "## Aim\n",
        "In this lab we are going to solve two simple [OpenAI Gym](https://gym.openai.com/) environments using [Q-Learning](https://en.wikipedia.org/wiki/Q-learning). Specifically, the [CartPole-v0](https://gym.openai.com/envs/CartPole-v0/) and [MountainCar-v0](https://gym.openai.com/envs/MountainCar-v0/) environments.\n",
        "\n",
        "We will try to create a table containing the expected reward for each combination of a *state* and *action*. We will use this table to choose the (hopefully) best action given the state the system is in.\n",
        "\n",
        "While this may not be the most advanced or complicated model there is, it is perfect for this task! Furthermore, it can be trained in a relatively short time!\n",
        "\n",
        "## Runtime and environment\n",
        "This [Jupyter Notebook](https://jupyterlab.readthedocs.io/en/latest/) was made to run on Google Colab. For this training, we recommend using the Google Colab environment.\n",
        "\n",
        "Please read the [instructions on Google Colab](https://medium.com/swlh/the-best-place-to-get-started-with-ai-google-colab-tutorial-for-beginners-715e64bb603b) to get started quickly. It behaves similar to Jupyter Notebook, Jupyter Hub and Jupyter Lab, so if you have any experience with those, you're good to go!\n",
        "\n",
        "Some notes on Google Colab:\n",
        "- **Processes in Google Colab won't run forever**. These may be terminated at any time when the platform is crowded, and *will definitely* terminate after 12 hours. To maintain persistency, you can attach the session to **Google Drive** and have your models persist themselves to the Google Drive periodically.\n",
        "- You can enable GPU or TPU support! You can find this option under *Runtime* -> *Change runtime type*.\n",
        "- After installing dependencies, you need to restart the runtime in order to actually use them.\n",
        "\n",
        "If you want to run the code on your own platform or system, you need to keep a few things in mind:\n",
        "- The dependencies you need to install may differ from the ones we installed here. The installed dependencies are suitable for Google Colab, Ubuntu, and Debian.\n",
        "- Since Google Colab isn't attached to a monitor, we render the output to a video file. On your own machine the built-in render method from OpenAI's Gym may suffice.\n",
        "- The default paths use Google Drive! Change these.\n",
        "\n",
        "## Info Support\n",
        "This assignment was developed by Info Support. Looking for a graduation project or job? Check out their website: https://carriere.infosupport.com/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7mfjQyuT_zV"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_LwZ18PXsaL"
      },
      "source": [
        "Some dependencies need to be installed for the code to work. Furthermore, we will define some methods which allow us to show the OpenAI Gym renderings in this (headless) Google Colab environment.\n",
        "\n",
        "You only have to run these and don't need to change any of the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBdwK87YUI9Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "outputId": "1966770b-eb62-42ce-ef9e-fb3e09da86d0"
      },
      "source": [
        "# Install dependencies\n",
        "\"\"\"Note: if you are running this code on your own machine, you probably don't need all of these.\n",
        "   Start with 'pip install gym' and install more packages if you run into errors.\"\"\"\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg cmake > /dev/null 2>&1\n",
        "\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1\n",
        "!pip install colabgymrender"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/15/5041473f5d142ee93bf1593deb8f932e27a078f6f04e2020cf44044f72c5/setuptools-56.2.0-py3-none-any.whl (785kB)\n",
            "\r\u001b[K     |▍                               | 10kB 16.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 22.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 27.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 29.3MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 29.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 61kB 22.4MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 22.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 23.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 92kB 24.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 102kB 25.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 112kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 122kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 133kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 143kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 153kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 163kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 174kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 184kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 204kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 215kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 225kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 235kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 245kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 256kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 266kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 276kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 286kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 296kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 307kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 317kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 327kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 337kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 348kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 358kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 368kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 378kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 389kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 399kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 409kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 419kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 430kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 440kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 450kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 460kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 471kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 481kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 491kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 501kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 512kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 522kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 532kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 542kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 552kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 563kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 573kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 583kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 593kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 604kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 614kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 624kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 634kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 645kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 655kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 665kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 675kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 686kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 696kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 706kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 716kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 727kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 737kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 747kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 757kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 768kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 778kB 25.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 788kB 25.0MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Found existing installation: setuptools 56.1.0\n",
            "    Uninstalling setuptools-56.1.0:\n",
            "      Successfully uninstalled setuptools-56.1.0\n",
            "Successfully installed setuptools-56.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting colabgymrender\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/97/eab3f4ef460cc79b811c37c3be2d05967696605774868b6556e04e6ae6f8/colabgymrender-1.0.8.tar.gz\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from colabgymrender) (0.2.3.5)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from colabgymrender) (5.5.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from colabgymrender) (4.1.2.30)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (from colabgymrender) (2.1)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (2.4.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (1.19.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (56.2.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (5.0.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (1.0.18)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay->colabgymrender) (0.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy->colabgymrender) (7.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->colabgymrender) (0.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->colabgymrender) (0.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->colabgymrender) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->colabgymrender) (0.2.5)\n",
            "Building wheels for collected packages: colabgymrender\n",
            "  Building wheel for colabgymrender (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colabgymrender: filename=colabgymrender-1.0.8-cp37-none-any.whl size=2511 sha256=590f989579e2b88f37b99fb0f804b6207487d7a9725d2d1eb562cd42ca9761d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/d1/e8/ef1d4f6e536cc6b965b28c859ccd2a7f7ab123b94ef4007712\n",
            "Successfully built colabgymrender\n",
            "Installing collected packages: colabgymrender\n",
            "Successfully installed colabgymrender-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7IG_wxod9mW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad92724f-76a7-4859-e8ee-7d04e0c2273d"
      },
      "source": [
        "# Imports for helper functions\n",
        "import base64\n",
        "import io\n",
        "import math\n",
        "from pathlib import Path\n",
        "\n",
        "import gym\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from colabgymrender.recorder import Recorder\n",
        "from google.colab import drive\n",
        "from gym.wrappers import Monitor\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3112960/45929032 bytes (6.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6512640/45929032 bytes (14.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b9437184/45929032 bytes (20.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12591104/45929032 bytes (27.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15949824/45929032 bytes (34.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19111936/45929032 bytes (41.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b22192128/45929032 bytes (48.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b25436160/45929032 bytes (55.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28573696/45929032 bytes (62.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31653888/45929032 bytes (68.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b34824192/45929032 bytes (75.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38043648/45929032 bytes (82.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41263104/45929032 bytes (89.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b44531712/45929032 bytes (97.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFDD54_Afgs4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3f6173-2d57-4a22-a9a9-5f2417b90da5"
      },
      "source": [
        "# Mount your Google Drive. By doing so, you can store any output, models, videos, and images persistently.\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJeiCQFRgnSj"
      },
      "source": [
        "# Create a directory to store the data for this lab. Feel free to change this.\n",
        "data_path = Path('/content/gdrive/My Drive/Colab Notebooks/HU_RL/part1')\n",
        "data_path.mkdir(parents=True, exist_ok=True)\n",
        "video_path = data_path / 'video'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU2ZsnBEelqW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0eeeb9b-3672-40ea-8a0b-0373514943da"
      },
      "source": [
        "# Define helper functions to visually show what the models are doing.\n",
        "%matplotlib inline\n",
        "\n",
        "gym.logger.set_level(gym.logger.ERROR)\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "def show_video():\n",
        "    # Display the stored video file\n",
        "    # Credits: https://star-ai.github.io/Rendering-OpenAi-Gym-in-Colaboratory/\n",
        "    mp4list = list(data_path.glob('video/*.mp4'))\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[-1]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "            </video>'''.format(encoded.decode('ascii'))))\n",
        "    else: \n",
        "        print('Could not find video')\n",
        "\n",
        "\n",
        "def record_episode(idx):\n",
        "    # This determines which episodes to record.\n",
        "    # Since the video rendering in the OpenAI Gym is a bit buggy, we simply override it and decide\n",
        "    # whether or not to render inside of our training loop.\n",
        "    return True\n",
        "\n",
        "    \n",
        "def video_env(env):\n",
        "    # Wraps the environment to write its output to a video file\n",
        "    env = Monitor(env, video_path, video_callable=record_episode, force=True)\n",
        "    return env\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f11386d6b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShMPjUFXiwli"
      },
      "source": [
        "# Test the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3hAfAGhi4KK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "37702b5e-a7c7-4b56-8b98-49c90ccfa533"
      },
      "source": [
        "\"\"\"We will use a basic OpenAI Gym examle: CartPole-v0.\n",
        "In this example, we will try to balance a pole on a cart.\n",
        "This is similar to kids (and.. grown-ups) trying to balance sticks on their hands.\n",
        "\n",
        "Check out the OpenAI Gym documentation to learn more: https://gym.openai.com/docs/\"\"\"\n",
        "\n",
        "# Create the desired environment\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "\n",
        "# Wrap the environment, to make sure we get to see a fancy video\n",
        "env = video_env(env)\n",
        "\n",
        "# Before you can use a Gym environment, it needs to be reset.\n",
        "state = env.reset()\n",
        "\n",
        "# Perform random actions untill we drop the stick. Just as an example.\n",
        "done = False\n",
        "while not done:\n",
        "    env.render()\n",
        "    # The action_space contains all possible actions we can take.\n",
        "    random_action = env.action_space.sample() \n",
        "\n",
        "    # After each action, we end up in a new state and receive a reward.\n",
        "    # When we drop the pole (more than 12 degrees), or balance it long enough (200 steps),\n",
        "    # or drive off the screen, done is set to True.\n",
        "    state, reward, done, info = env.step(random_action)\n",
        "\n",
        "# Show the results!\n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'We will use a basic OpenAI Gym examle: CartPole-v0.\\nIn this example, we will try to balance a pole on a cart.\\nThis is similar to kids (and.. grown-ups) trying to balance sticks on their hands.\\n\\nCheck out the OpenAI Gym documentation to learn more: https://gym.openai.com/docs/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "            </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-O3zaP6q4-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49387eaa-a87f-49b9-f192-696f0a77d1da"
      },
      "source": [
        "# Neat, it did something (randomly)! \n",
        "\n",
        "# In order to train the system, we will try to predict the reward a certain actions yields given the state of the system.\n",
        "# But what is the state anyway?\n",
        "\n",
        "# In this environment, the state represents the cart's position and velocity, and the pole's angle and velocity.\n",
        "\n",
        "# Let's check out the current state\n",
        "print(f'State array: {state}')\n",
        "print(f'Cart position: {state[0]} (range: [-4.8, 4.8])')\n",
        "print(f'Cart velocity: {state[1]} (range: [-inf, inf])')\n",
        "print(f'Pole angle: {state[2]} (range: [-0.418, 0.418])')\n",
        "print(f'Pole velocity: {state[3]} (range [-inf, inf])')\n",
        "\n",
        "# You can find out the minimum and maximum possible observation values using:\n",
        "print(f'Low observation space:', env.observation_space.low)\n",
        "print(f'High observation space:', env.observation_space.low)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "State array: [ 0.15530884  0.59646372 -0.21915337 -1.16321568]\n",
            "Cart position: 0.15530884215659443 (range: [-4.8, 4.8])\n",
            "Cart velocity: 0.5964637220692551 (range: [-inf, inf])\n",
            "Pole angle: -0.21915337000652094 (range: [-0.418, 0.418])\n",
            "Pole velocity: -1.1632156811278793 (range [-inf, inf])\n",
            "Low observation space: [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
            "High observation space: [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhQlBt2hUAQ2"
      },
      "source": [
        "# Implement Q-Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFsyJOo5GrZe"
      },
      "source": [
        "## Task\n",
        "Implement Q-Learning and find suitable parameters to reach a 200 reward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDvyHdRyRtdq"
      },
      "source": [
        "# Define parameters - Fill in the dots\n",
        "\n",
        "num_episodes = 10000\n",
        "num_episodes_between_status_update = 500\n",
        "num_episodes_between_videos = 5000\n",
        "\n",
        "learning_rate = 0.001         # also known as: alpha\n",
        "discount = 0.95              # also known as: gamma\n",
        "epsilon = 0.25\n",
        "\n",
        "# Epsilon decay\n",
        "epsilon_decay = 0.995 #TODO\n",
        "\n",
        "# Discretization\n",
        "scale = 10\n",
        "\n",
        "upper_bounds = [env.observation_space.high[0], 0.5, env.observation_space.high[2], math.radians(50) / 1.]\n",
        "lower_bounds = [env.observation_space.low[0], -0.5, env.observation_space.low[2], -math.radians(50) / 1.]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0S8rYCWT15s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b48ab086-6ec2-4936-e5bd-68304ff4c797"
      },
      "source": [
        "## Q-Table creation\n",
        "\n",
        "# As seen before, the state consists of 4 floating point values.\n",
        "# It makes sense to discretize these values (read: place them in buckets), to reduce the state space and therefore the Q-table size\n",
        "state_shape = [4, 4, 6, 6]      # For instance: [4, 4, 6, 6], or [10] * 4, or [200, 200, 100, 100]\n",
        "\n",
        "# Define the initial Q table as a random uniform distribution\n",
        "q_table = np.random.uniform(low=-2, high=0, size=(state_shape + [env.action_space.n]))\n",
        "\n",
        "print('Initial Q table:', q_table.shape)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Q table: (4, 4, 6, 6, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4Cp8cNtUcDf"
      },
      "source": [
        "# Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SMMA_KceHrx"
      },
      "source": [
        "# Functions\n",
        "\n",
        "def discretize_state(obs=env.observation_space.shape):\n",
        "    \"\"\"\n",
        "    A Q-table cannot practically handle infinite states, so limit the state space by\n",
        "    discretizing the state into buckets.\n",
        "    \"\"\"\n",
        "    discretized = list()\n",
        "    for i in range(len(obs)):\n",
        "        scaling = ((obs[i] + abs(lower_bounds[i]))/(upper_bounds[i] - lower_bounds[i]))\n",
        "        new_obs = int(round((state_shape[i] - 1) * scaling))\n",
        "        new_obs = min(state_shape[i] - 1, max(0, new_obs))\n",
        "        discretized.append(new_obs)\n",
        "    return tuple(discretized)\n",
        "\n",
        "def take_action(discrete_state, epsilon):\n",
        "    # Take an action to either explore or exploit based on epsilon\n",
        "    if (np.random.random() < epsilon):\n",
        "        action = env.action_space.sample()\n",
        "    else:\n",
        "        action = np.argmax(q_table[discrete_state])\n",
        "    return action\n",
        "\n",
        "def estimated_max_for_next_state(discrete_state):\n",
        "    # What's the best expected Q-value for the next state?\n",
        "    estimated_max = np.max(q_table[discrete_state])\n",
        "    return estimated_max\n",
        "\n",
        "def new_q_value(discrete_state, action, max_future_q):\n",
        "    # Calculate the new Q-value\n",
        "    Q_table[state][action] += (get_learning_rate(e) * (reward + gamma * np.max(Q_table[new_state])- Q_table[state][action]))\n",
        "    current_q = ...\n",
        "    new_q = ...\n",
        "    return new_q\n",
        "\n",
        "def decayed_epsilon(epsilon, episode):\n",
        "    # Optionally, decay the epsilon value\n",
        "    pass\n",
        "    return epsilon"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgjdOJZBp62o",
        "outputId": "c668473f-547a-4599-eb33-37a110a2122e"
      },
      "source": [
        "np.argmax(q_table[discretize_state()])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMUc3G164cA7"
      },
      "source": [
        "# Time to train the system\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    state = env.reset() # Don't forget to reset the environment between episodes\n",
        "    current_state_disc = discretize_state(state)\n",
        "\n",
        "    reward_sum = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        if (episode + 1) % num_episodes_between_videos == 0:\n",
        "            env.render()\n",
        "\n",
        "        # Take an action by exploration or exploitation\n",
        "        action = take_action(current_state_disc, epsilon)\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        new_state_disc = discretize_state(new_state)\n",
        "\n",
        "        # Calculate the total reward\n",
        "        reward_sum += reward\n",
        "\n",
        "        if not done:\n",
        "            # Retrieve the maximum estimated value for the next state\n",
        "            max_future_q = estimated_max_for_next_state(new_state_disc)\n",
        "\n",
        "            # Calculate the new value (note: Bellman equation)\n",
        "            new_q = new_q_value(current_state_disc, action, max_future_q)\n",
        "            q_table[current_state_disc + (action,)] = new_q\n",
        "        else:\n",
        "            # Render the video\n",
        "            if (episode + 1) % num_episodes_between_status_update == 0:\n",
        "                env.render()\n",
        "                print(f'Total reward at episode {episode + 1}: {reward_sum}')\n",
        "\n",
        "        # Prepare for the next loop\n",
        "        current_state_disc = new_state_disc\n",
        "\n",
        "    # Decay epsilon\n",
        "    epsilon = decayed_epsilon(epsilon, episode)\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RbC9GKag15q"
      },
      "source": [
        "# MountainCar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0oyL2bxg_1j"
      },
      "source": [
        "Now apply the things you've learned to the MountainCar problem. Please note that the observable space differs from the previous problem. Thus, before you start training, you need to learn more about thethis new environment.\n",
        "\n",
        "Here is some code to help you get started.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWzVnM10g4Oc"
      },
      "source": [
        "# Create the desired environment\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "\n",
        "# Wrap the environment, to make sure we get to see a fancy video\n",
        "env = video_env(env)\n",
        "\n",
        "# Before you can use a Gym environment, it needs to be reset.\n",
        "state = env.reset()\n",
        "\n",
        "# Perform random actions untill we drop the stick. Just as an example.\n",
        "done = False\n",
        "while not done:\n",
        "   \n",
        "    # Explore and take actions\n",
        "    pass\n",
        "\n",
        "    # Remove the line below when you have created an implementation you want to test.\n",
        "    done = True\n",
        "\n",
        "# Show the results!\n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}